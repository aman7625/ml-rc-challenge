{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I3hn6odOPrli"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9zQdmlJkuvQO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1w0KDWa4YLM"
   },
   "outputs": [],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaOJeEmruvQR",
    "outputId": "c3f57379-5520-44ff-918a-6d0c1b91ccc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/content/data')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = pathlib.Path('/content/data')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A3AS_FS4uvQV",
    "outputId": "24ec3599-2eb4-41df-ba1c-2c8c9d920769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5505\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wAq0TolQuvQX"
   },
   "outputs": [],
   "source": [
    "#eye - EyeFrame , avi - Aviator, ova - Oval, rec - Rectangle, way - Wayfarer\n",
    "#sun - Sunglasses\n",
    "#non - non power reading\n",
    "\n",
    "images_dict = {\n",
    "    'eye_avi': list(data_dir.glob('eye_avi/*')),\n",
    "    'eye_ova': list(data_dir.glob('eye_ova/*')),\n",
    "    'eye_rec': list(data_dir.glob('eye_rec/*')),\n",
    "    'eye_way': list(data_dir.glob('eye_way/*')),\n",
    "    'non_avi': list(data_dir.glob('non_avi/*')),\n",
    "    'non_ova': list(data_dir.glob('non_ova/*')),\n",
    "    'non_rec': list(data_dir.glob('non_rec/*')),\n",
    "    'non_way': list(data_dir.glob('non_way/*')),\n",
    "    'sun_avi': list(data_dir.glob('sun_avi/*')),\n",
    "    'sun_ova': list(data_dir.glob('sun_ova/*')),\n",
    "    'sun_rec': list(data_dir.glob('sun_rec/*')),\n",
    "    'sun_way': list(data_dir.glob('sun_way/*')),\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HH6XMl8-uvQa"
   },
   "outputs": [],
   "source": [
    "images_label_dict = {\n",
    "    'eye_avi': 0,\n",
    "    'eye_ova': 1,\n",
    "    'eye_rec': 2,\n",
    "    'eye_way': 3,\n",
    "    'non_avi': 4,\n",
    "    'non_ova': 5,\n",
    "    'non_rec': 6,\n",
    "    'non_way': 7,\n",
    "    'sun_avi': 8,\n",
    "    'sun_ova': 9,\n",
    "    'sun_rec': 10,\n",
    "    'sun_way': 11,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqfWsRDiRHw1"
   },
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "moEtqgpSuvQd",
    "outputId": "d817e8cb-5049-4e5f-a90f-faf8546d7245"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 12:38:09.567588: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-10-03 12:38:09.567655: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (745c20f01168): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "#Using the pre-trained mobilenetV2 model except the last layer \n",
    "\n",
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNPjZ3bduvQf",
    "outputId": "d2cbd399-254f-4372-9c84-3fcaac374941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 2,273,356\n",
      "Trainable params: 15,372\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Adding a layer at the top of the model for classification\n",
    "\n",
    "classes = 12\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  pretrained_model ,\n",
    "  tf.keras.layers.Dense(classes)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HewguB4nuvQr"
   },
   "outputs": [],
   "source": [
    "#Reading eyewear images from disk into numpy array using opencv\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for eyewear, images in images_dict.items():\n",
    "    for image in images:\n",
    "        img = cv2.imread(str(image))\n",
    "        resized_img = cv2.resize(img,(224,224))\n",
    "        X.append(resized_img)\n",
    "        y.append(images_label_dict[eyewear])\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FM0mlF02Pak1"
   },
   "source": [
    "# Splitting Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqQ491NvuvQs",
    "outputId": "226eb8bf-d63b-45c0-d09d-61fde55a4d52"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "#Preprocessing the data\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwBi4YWPRZ0C"
   },
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ho-d-CB6uvQt",
    "outputId": "20bbbe79-c583-485d-bae9-b66faf205364"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2485518336 bytes == 0x56505d3f2000 @  0x7f96955ec1e7 0x7f968be2346e 0x7f968be73c7b 0x7f968be73d97 0x7f968be73fe9 0x7f968be76d7d 0x7f9631a8b7d0 0x7f9631a37e30 0x7f9631a38a79 0x564e2bcb20a4 0x564e2bc72c52 0x564e2bce64d9 0x564e2bce09ee 0x564e2bc73bda 0x564e2bce1915 0x564e2bc73afa 0x564e2bce1915 0x564e2bce09ee 0x564e2bc73bda 0x564e2bce2737 0x564e2bce09ee 0x564e2bc73bda 0x564e2bce2737 0x564e2bce09ee 0x564e2bc73bda 0x564e2bce2737 0x564e2bce09ee 0x564e2bbb2e2b 0x564e2bce2fe4 0x564e2bce0ced 0x564e2bc73bda\n",
      "2021-10-03 12:39:07.809325: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129/129 [==============================] - 103s 770ms/step - loss: 0.8790 - acc: 0.7229\n",
      "Epoch 2/10\n",
      "129/129 [==============================] - 99s 770ms/step - loss: 0.4980 - acc: 0.8314\n",
      "Epoch 3/10\n",
      "129/129 [==============================] - 99s 770ms/step - loss: 0.4156 - acc: 0.8600\n",
      "Epoch 4/10\n",
      "129/129 [==============================] - 99s 767ms/step - loss: 0.3665 - acc: 0.8760\n",
      "Epoch 5/10\n",
      "129/129 [==============================] - 99s 768ms/step - loss: 0.3361 - acc: 0.8883\n",
      "Epoch 6/10\n",
      "129/129 [==============================] - 99s 767ms/step - loss: 0.3044 - acc: 0.8970\n",
      "Epoch 7/10\n",
      "129/129 [==============================] - 99s 767ms/step - loss: 0.2862 - acc: 0.9007\n",
      "Epoch 8/10\n",
      "129/129 [==============================] - 99s 768ms/step - loss: 0.2708 - acc: 0.9087\n",
      "Epoch 9/10\n",
      "129/129 [==============================] - 99s 770ms/step - loss: 0.2533 - acc: 0.9167\n",
      "Epoch 10/10\n",
      "129/129 [==============================] - 100s 774ms/step - loss: 0.2371 - acc: 0.9268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96083c6ed0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "  optimizer=\"adam\",\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ofRanvRgMK"
   },
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6CdBI6ruvQu",
    "outputId": "287e3657-001b-4f05-e07e-297ccbd6f6ef",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 34s 757ms/step - loss: 0.3860 - acc: 0.8758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38597458600997925, 0.8758170008659363]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2iVDkglqRm6D"
   },
   "source": [
    "# Exporting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-jt38uXguvQv"
   },
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model,'my_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8VkW28kvBpB"
   },
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s64xGvHfRuOq"
   },
   "source": [
    "# Deplyoing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFdTMCiwuvQv",
    "outputId": "00f8952c-0576-4962-cbd2-a4d2b2b7e3df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def load_model():\n",
    "    feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "    KerasLayer = hub.KerasLayer(feature_extractor_model, input_shape=(224, 224, 3), trainable=False)\n",
    "    model=tf.keras.models.load_model('/content/my_model.hdf5', custom_objects={'KerasLayer': KerasLayer})\n",
    "    return model\n",
    "\n",
    "def load_image(path):\n",
    "    img = image.load_img(path, target_size=(224,224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x\n",
    "\n",
    "def output_images(indexes, images):\n",
    "    output = []\n",
    "    for idx in indexes:\n",
    "        img = cv2.imread(images[idx])\n",
    "        st.image(img,use_column_width=True )\n",
    "        output.append(img)\n",
    "    return output\n",
    "\n",
    "#using feature extraction to display the similar images\n",
    "@st.cache(allow_output_mutation=True)\n",
    "def distance():\n",
    "    images_path = '/content/data'\n",
    "    image_extensions = ['.jpg','.png']\n",
    "    max_num_images = 10000\n",
    "\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(images_path) for f in filenames if os.path.splitext(f)[1].lower() in image_extensions]\n",
    "    if max_num_images < len(images):\n",
    "        images = [images[i] for i in sorted(random.sample(xrange(len(images)), max_num_images))]\n",
    "\n",
    "    #Appending the feature vector 'feat' to the list of features \n",
    "    features = []\n",
    "    for i, image_path in enumerate(images):\n",
    "        img, x = load_image(image_path);\n",
    "        feat = model.predict(x)[0]\n",
    "        features.append(feat)\n",
    "    \n",
    "    features = np.array(features)\n",
    "\n",
    "    #reducing the reduncany in features i.e reducing the number of features in feature vector to 4\n",
    "    pca = PCA(n_components=4)\n",
    "    pca.fit(features)\n",
    "    pca_features = pca.transform(features)\n",
    "    return pca, pca_features, images\n",
    "\n",
    "\n",
    "def similar_images(img, pca, pca_features, col_images):\n",
    "    img = img.resize((224,224))    \n",
    "    x = np.asarray(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    model = load_model()\n",
    "    new_feat = model.predict(x)\n",
    "    new_pca_feat = pca.transform(new_feat)[0]\n",
    "    \n",
    "    #using cosine distance as the dissimilarity metric \n",
    "    distances = [ scipy.spatial.distance.cosine(new_pca_feat, feat) for feat in pca_features ]\n",
    "    idx_closest = sorted(range(len(distances)), key=lambda k: distances[k])[0:10]  # grab first 10\n",
    "    results_image = output_images(idx_closest, col_images)\n",
    "\n",
    "\n",
    "with st.spinner('Model is being loaded..'):\n",
    "    model=load_model()\n",
    "    pca, pca_features, col_images = distance()\n",
    "\n",
    "st.write(\"\"\"\n",
    "         # Eyewear Classification\n",
    "         \"\"\"\n",
    "         )\n",
    "\n",
    "\n",
    "file = st.file_uploader(\"Please upload the file you want to classify\", type=[\"jpg\", \"png\"])\n",
    "st.set_option('deprecation.showfileUploaderEncoding', False)\n",
    "def import_and_predict(image_data, model):\n",
    "        size = (224,224)    \n",
    "        image = ImageOps.fit(image_data, size, Image.ANTIALIAS)\n",
    "        image = np.asarray(image)\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        img_reshape = img[np.newaxis,...]\n",
    "        prediction = model.predict(img_reshape)\n",
    "        return prediction\n",
    "\n",
    "if file is None:\n",
    "    st.text(\"Please upload an image file\")\n",
    "else:\n",
    "    st.write(\"Uploaded Image\")\n",
    "    image = Image.open(file)\n",
    "    st.image(image, use_column_width=True)\n",
    "    predictions = import_and_predict(image, model)\n",
    "    score = tf.nn.softmax(predictions[0])\n",
    "    class_names = {0: \"EyeFrame-Aviator\",1: \"EyeFrame-Oval\",2: \"EyeFrame-Rectangle\",3: \"EyeFrame-Wayfarer\",\n",
    "                   4: \"NPR-Aviator\",5: \"NPR-Oval\",6: \"NPR-Rectangle\",7: \"NPR-Wayfarer\",\n",
    "                   8:\"Sunglasses-Aviator\",9: \"Sunglasses-Oval\",10: \"Sunglasses-Rectangle\",11: \"Sunglasses-Wayfarer\"}\n",
    "    st.write(\n",
    "    \"This image most likely belongs to {}\"\n",
    "    .format(class_names[np.argmax(score)])\n",
    "    )\n",
    "    pca, pca_features, col_images = distance()\n",
    "    st.write(\"Most Similar Images\")\n",
    "    similar_images(image, pca, pca_features, col_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d9Lr9nTJuvQw",
    "outputId": "55ba2643-915c-4bc5-f7c2-27f54fc0ff2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-03 12:56:23--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 54.237.133.81, 18.205.222.128, 54.161.241.46, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|54.237.133.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13832437 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.19M  6.12MB/s    in 2.2s    \n",
      "\n",
      "2021-10-03 12:56:26 (6.12 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nONSLh-4uvQx",
    "outputId": "bbe5e15a-008c-4cbf-8e97-ffe345545f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n"
     ]
    }
   ],
   "source": [
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "SRDLQiyluvQx"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 8501 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xbhvzQFYuvQy",
    "outputId": "5f4b5cb2-9d0b-4642-ce2a-688cc6a60251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute the next cell and the go to the following URL: https://0fc2-35-227-30-197.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    'import sys, json; print(\"Execute the next cell and the go to the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBW1fBnkvVuT",
    "outputId": "ed83d1a6-bc24-4e6b-f58c-29415b943d03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.227.30.197:8501\u001b[0m\n",
      "\u001b[0m\n",
      "2021-10-03 12:58:34.505 Using /tmp/tfhub_modules to cache modules.\n",
      "2021-10-03 12:58:34.868875: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-10-03 12:58:34.868941: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (745c20f01168): /proc/driver/nvidia/version does not exist\n",
      "2021-10-03 12:58:40.130040: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run /content/app.py"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ml_rc_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
